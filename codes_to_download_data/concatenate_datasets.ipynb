{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5f092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983d0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "import shutil\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def _sample_file_to_temp(\n",
    "    in_path: str,\n",
    "    frac: float,\n",
    "    rename_cols: Optional[Dict[str, str]],\n",
    "    seed: int,\n",
    "    tmpdir: str,\n",
    "    read_csv_kwargs: Optional[Dict] = None,\n",
    ") -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Worker: read one CSV, Bernoulli-sample rows, write to a temporary CSV (with header),\n",
    "    and return (temp_path, n_rows_written). If no rows selected, returns (\"\", 0).\n",
    "    \"\"\"\n",
    "    if read_csv_kwargs is None:\n",
    "        read_csv_kwargs = {}\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df = pd.read_csv(in_path, **read_csv_kwargs)\n",
    "    if rename_cols:\n",
    "        df = df.rename(columns=rename_cols)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        return (\"\", 0)\n",
    "\n",
    "    mask = rng.random(len(df)) < frac\n",
    "    sampled = df.loc[mask]\n",
    "    if sampled.empty:\n",
    "        return (\"\", 0)\n",
    "\n",
    "    fd, tmp_path = tempfile.mkstemp(suffix=\".csv\", dir=tmpdir)\n",
    "    os.close(fd)  # we'll open it via pandas\n",
    "    sampled.to_csv(tmp_path, index=False)  # writes header + data\n",
    "    return (tmp_path, len(sampled))\n",
    "\n",
    "\n",
    "def _append_file_skipping_header(src_path: str, dst_fh):\n",
    "    \"\"\"\n",
    "    Append `src_path` CSV to already-open destination file handle `dst_fh`,\n",
    "    skipping the first line (header) in src.\n",
    "    \"\"\"\n",
    "    with open(src_path, \"rb\") as sf:\n",
    "        # Skip first line (header)\n",
    "        _ = sf.readline()\n",
    "        # Stream copy the rest\n",
    "        shutil.copyfileobj(sf, dst_fh)\n",
    "\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "def sample_from_csv_folder_parallel(\n",
    "    folder: str,\n",
    "    file_patterns: List[str] = [\"SPLUS-s*.csv\"],  # ← now a list\n",
    "    frac: float = 1,\n",
    "    rename_cols: Optional[Dict[str, str]] = None,\n",
    "    random_state: int = 42,\n",
    "    max_workers: int = 4,\n",
    "    out_csv: str = \"sampled.csv\",\n",
    "    read_csv_kwargs: Optional[Dict] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Truly parallel sampling across CSV files:\n",
    "      - file_patterns can be a list of glob-style patterns (e.g., [\"SPLUS-*.csv\", \"Gaia-*.csv\"])\n",
    "      - Only matching files are included.\n",
    "    \"\"\"\n",
    "    all_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    files = []\n",
    "    for f in all_files:\n",
    "        base = os.path.basename(f)\n",
    "        if any(fnmatch.fnmatch(base, pat) for pat in file_patterns):\n",
    "            files.append(f)\n",
    "\n",
    "    if not files:\n",
    "        open(out_csv, \"w\").close()\n",
    "        return out_csv\n",
    "\n",
    "    if os.path.exists(out_csv):\n",
    "        os.remove(out_csv)\n",
    "\n",
    "    tmpdir = tempfile.mkdtemp(prefix=\"csv_parts_\")\n",
    "    non_empty_parts: List[Tuple[str, int]] = []\n",
    "\n",
    "    try:\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            futures = {\n",
    "                ex.submit(\n",
    "                    _sample_file_to_temp,\n",
    "                    path,\n",
    "                    frac,\n",
    "                    rename_cols,\n",
    "                    random_state + i,\n",
    "                    tmpdir,\n",
    "                    read_csv_kwargs,\n",
    "                ): path\n",
    "                for i, path in enumerate(files)\n",
    "            }\n",
    "\n",
    "            for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Sampling (parallel)\"):\n",
    "                tmp_path, n_rows = fut.result()\n",
    "                if n_rows > 0 and tmp_path:\n",
    "                    non_empty_parts.append((tmp_path, n_rows))\n",
    "\n",
    "        if not non_empty_parts:\n",
    "            open(out_csv, \"w\").close()\n",
    "            return out_csv\n",
    "\n",
    "        # Merge\n",
    "        first_part = non_empty_parts[0][0]\n",
    "        with open(out_csv, \"wb\") as out_fh:\n",
    "            with open(first_part, \"rb\") as fp:\n",
    "                shutil.copyfileobj(fp, out_fh)\n",
    "            for part_path, _ in non_empty_parts[1:]:\n",
    "                _append_file_skipping_header(part_path, out_fh)\n",
    "\n",
    "    finally:\n",
    "        shutil.rmtree(tmpdir, ignore_errors=True)\n",
    "\n",
    "    return out_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ecb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling (parallel): 100%|██████████| 1212/1212 [03:39<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df = sample_from_csv_folder_parallel(\n",
    "    '../data/field_catalogs/matches', \n",
    "    file_pattern=[\"SPLUS-s*.csv\"],\n",
    "    frac=1, \n",
    "    max_workers=8,\n",
    "    rename_cols={'gaia_parallax': 'parallax'},\n",
    "    out_csv='../data/oficial/SPLUS-s.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c953726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling (parallel):  85%|████████▌ | 1005/1182 [05:47<00:42,  4.20it/s] /tmp/ipykernel_189222/2059969538.py:28: DtypeWarning: Columns (179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(in_path, **read_csv_kwargs)\n",
      "Sampling (parallel): 100%|██████████| 1182/1182 [06:41<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df = sample_from_csv_folder_parallel(\n",
    "    '../data/field_catalogs/matches', \n",
    "    file_patterns=[\"SPLUS-n*\", \"HYDRA*\", \"STRIPE*\"],\n",
    "    frac=1, \n",
    "    max_workers=8,\n",
    "    rename_cols={'gaia_parallax': 'parallax'},\n",
    "    out_csv='../data/oficial/SPLUS-n_HYDRA_STRIPE.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af72413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling (parallel): 100%|██████████| 146/146 [06:24<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "df = sample_from_csv_folder_parallel(\n",
    "    '../data/field_catalogs/splus_gaia_crowded/matches', \n",
    "    file_patterns=[\"MC*\"],\n",
    "    frac=1, \n",
    "    max_workers=8,\n",
    "    rename_cols={'gaia_parallax': 'parallax'},\n",
    "    out_csv='../data/oficial/MC.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20a8a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling (parallel): 100%|██████████| 460/460 [25:29<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "df = sample_from_csv_folder_parallel(\n",
    "    '../data/field_catalogs/splus_gaia_crowded/matches', \n",
    "    file_patterns=[\"SPLUS-b*\", \"SPLUS-d*\"],\n",
    "    frac=1,\n",
    "    max_workers=8,\n",
    "    rename_cols={'gaia_parallax': 'parallax'},\n",
    "    out_csv='/mnt/hdcasa/splus_gaia/oficial/SPLUS-b_SPLUS-d.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217df32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
